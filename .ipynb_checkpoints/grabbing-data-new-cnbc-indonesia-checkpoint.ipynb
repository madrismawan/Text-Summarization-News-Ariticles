{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import Exception\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from requests import get\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deklarasi Connection Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"db-berita-mca\"  \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi-Fungsi Pada Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel kebawah tersebut merupakan fungsi-fungsi yang dibuat untuk sebuah action pada database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[simpanDatabase] Menyimpan Data Kedalam Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpanDatabase(mydb,data):\n",
    "    mycursor = mydb.cursor()\n",
    "    sql = \"INSERT INTO tb_berita (media,judul_berita,label,penulis,release_date,url,content) VALUES (%s,%s,%s,%s,%s,%s,%s)\"\n",
    "    mycursor.execute(sql, data)\n",
    "    mydb.commit()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ValidasiDataDatabase] Mengecek kedalam database apakah data tersebut sudah pernah di simpan atau belum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validasiDataDatabase(mydb,dataBerita):\n",
    "    mycursor = mydb.cursor()\n",
    "    sql = \"SELECT * FROM tb_berita WHERE url = %s\"\n",
    "    dataUrl = dataBerita\n",
    "    url = (dataBerita,)\n",
    "    mycursor.execute(sql, url)\n",
    "    myresult = mycursor.fetchall()\n",
    "    return myresult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semua Halaman Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dibawah ini adalah source yang digunakan dalam mengambil berapa panjang dari halaman website CBNC Indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllPageWebsite(url,keyword):\n",
    "    if(keyword == \"\"):\n",
    "        urlGet = (url+\"/indeks\")\n",
    "    else:\n",
    "        urlGet = (url+\"/search?query=\"+keyword)\n",
    "        \n",
    "    try:\n",
    "        soup = BeautifulSoup(get(urlGet).text, 'lxml')\n",
    "        getAllPage= soup.find('div','paging text_center gtm_paging')\n",
    "        page_link = getAllPage.select('a')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    try:\n",
    "        for page in page_link:\n",
    "            if(page.text != \"\"):\n",
    "                lastPage = page.text\n",
    "        return lastPage\n",
    "    except Exception as e:\n",
    "        print(\"Tidak Terdapat Data pada Pencarian anda tersebut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data URL Detail Berita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi dibawah ini ngambil semua url berdasarkan indeks page yang tersedia pada website CBNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrlInPage(url,keyword,page):\n",
    "    urlDetailData = []\n",
    "    for page in range(page): \n",
    "        if(keyword == \"\"):\n",
    "            urlGet = (url+\"/indeks/{}\".format(page+1))\n",
    "        else:\n",
    "            urlGet = (url+\"/search?query=\"+keyword+\"&p={}\".format(page+1))\n",
    "            \n",
    "        indeksPage = get(urlGet)\n",
    "        soup = BeautifulSoup(indeksPage.text, 'html.parser')\n",
    "        contents = soup.find_all('article')\n",
    "        for content in contents:\n",
    "            try:\n",
    "                news_url = content.find('a', href=True).get('href')\n",
    "                urlDetailData.append(news_url)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    return urlDetailData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Data Detail News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping data detail berdasarkan url yang diambil perhalaman diatas\n",
    "nah dibawah inin ni isi mau aku buatin buat ngecek gak double insert data aja dia deh wait\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapingDataDetailCNBC(urlDetailData,mydb):\n",
    "    for dataBerita in urlDetailData:\n",
    "            \n",
    "        myresult = validasiDataDatabase(mydb,dataBerita)\n",
    "        \n",
    "        if(len(myresult)==0):\n",
    "            try:\n",
    "                web_data = get(dataBerita)\n",
    "                soup = BeautifulSoup(web_data.text, 'html.parser')\n",
    "                header = soup.find('div', class_='jdl')\n",
    "                media = \"CBNC Indonesia\"\n",
    "                title = header.find('h1').text\n",
    "                author_class = header.find('div', class_='author').text.split(' ')\n",
    "                label = author_class[0]\n",
    "                author = ' '.join(author_class[2:])\n",
    "                release_date = header.find('div', class_='date').text\n",
    "                detail_text_class = soup.find('div', class_='detail_text')\n",
    "                texts = detail_text_class.find_all('p')\n",
    "                news_content = ' '.join([text.text for text in texts])\n",
    "\n",
    "\n",
    "                data = (media,title,label,author,release_date,dataBerita,news_content)\n",
    "                simpanDatabase(mydb,data)\n",
    "            except Exception as e:\n",
    "                continue    \n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi Utama Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.cnbcindonesia.com\"\n",
    "search = \"\"\n",
    "allPage = getAllPageWebsite(url,search)\n",
    "\n",
    "# parameter(url,keyword,page)\n",
    "urlDetail = getUrlInPage(url,search,1)\n",
    "\n",
    "scrapingDataDetailCNBC(urlDetail,mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callDataSourceNews(mydb):\n",
    "    mycursor = mydb.cursor()\n",
    "    mycursor.execute(\"SELECT link FROM tb_source_berita\")\n",
    "    myresult = mycursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mycursor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bb4d2077f9ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcallDataSourceNews\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-0952480683b5>\u001b[0m in \u001b[0;36mcallDataSourceNews\u001b[1;34m(mydb)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcallDataSourceNews\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmycursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT link FROM tb_source_berita\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmyresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmycursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mycursor' is not defined"
     ]
    }
   ],
   "source": [
    "callDataSourceNews(mydb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
