{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\risma\\Kuliah\\MCA\\Text-Summarization-News-Ariticles\\algoritma\\MMR.ipynb\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import import_ipynb\n",
    "import re\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import pandas as pd\n",
    "from algoritma.MMR import *\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from termcolor import colored\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deklarasi Connection Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat koneksi kedatabase lokal dengan database 'db-berita-mca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"db-berita-mca\"  \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat Fungsi Steaming Use Sastrawi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat stemmer pakai sastrawi \n",
    "Digunakan untuk melakukan steaming kalimat (menjadi kalimat dasar Menggunakan Library Sastrawi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengambil Data pada Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengambil data pada database,data yang diambil hanya 2 kolom saja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Krisis mainan jelang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Aset kripto (cryptoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Internet merupakan s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>225</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Asal muasal virus co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>226</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Dunia mata uang krip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>760</td>\n",
       "      <td>TRIBUNNEWS.COM - Sejumlah laga seru akan terha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>761</td>\n",
       "      <td>Laporan Reporter Tribunnews.com, Reza Deni TRI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>762</td>\n",
       "      <td>TRIBUNNEWS.COM - Persis Solo tak memiliki pili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>763</td>\n",
       "      <td>Laporan Wartawan Tribunnews.com, Mohammad Aliv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>764</td>\n",
       "      <td>TRIBUNNEWS.COM - Panasnya pertandingan Timnas ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>489 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            article\n",
       "0    217  Jakarta, CNBC Indonesia - Krisis mainan jelang...\n",
       "1    222  Jakarta, CNBC Indonesia - Aset kripto (cryptoc...\n",
       "2    224  Jakarta, CNBC Indonesia - Internet merupakan s...\n",
       "3    225  Jakarta, CNBC Indonesia - Asal muasal virus co...\n",
       "4    226  Jakarta, CNBC Indonesia - Dunia mata uang krip...\n",
       "..   ...                                                ...\n",
       "484  760  TRIBUNNEWS.COM - Sejumlah laga seru akan terha...\n",
       "485  761  Laporan Reporter Tribunnews.com, Reza Deni TRI...\n",
       "486  762  TRIBUNNEWS.COM - Persis Solo tak memiliki pili...\n",
       "487  763  Laporan Wartawan Tribunnews.com, Mohammad Aliv...\n",
       "488  764  TRIBUNNEWS.COM - Panasnya pertandingan Timnas ...\n",
       "\n",
       "[489 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"SELECT id, content FROM tb_berita\")\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "df = pd.DataFrame(myresult,columns=['id','article'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Stopword Lib & File Internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengambil data stopword bahasa indonesia yang pertama menggunakan file list dari stop word 917 dan menggunakan library nltk sebanyak panjang data 789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopWords():\n",
    "    r = open(\"stopwordlist-indonesia.txt\", \"r\")\n",
    "    readTxt = r.read()\n",
    "    idStopWord = readTxt.split() \n",
    "    return idStopWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_stopWordsNLTK():\n",
    "    stop_words = stopwords.words('indonesian')\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpan hasil summary ke database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menyimpan data yang telah dihasilakan melalui summary ke database dengan cara mengupdate data tersebut dan memasukan text summary pada field tersebut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpanSummary(mydb,summary,id):\n",
    "    mycursor = mydb.cursor()\n",
    "    id = int(id)\n",
    "    sql = \"UPDATE tb_berita SET summary = %s WHERE id = %s\"\n",
    "    param = (summary,id)\n",
    "    mycursor.execute(sql, param)\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proses Text Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tokenizeParagraftoKalimat, cleansingData, steamingData, indoStopWord]\n",
    "\n",
    "Fungsi diatas merupakan fungsi yang digunakan untuk melakukan preprocessing article sebuah berita, penjelasan mengenai fungsi akan dijelaskan lebih lanjut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tokenizeParagraftoKalimat]\n",
    "\n",
    "berfungsi sebagai tokenize pargraf menjadi bagian perkalimat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeParagraftoKalimat(paragraf):\n",
    "    tokenize = sent_tokenize(paragraf)\n",
    "    return tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cleansingData]\n",
    "\n",
    "berfungsi sebagai membersihkan data dari huruf tanda petik dan masih kata besar atau keceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansingData(text):\n",
    "    hasil = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    hasil = hasil.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[steamingData]\n",
    "\n",
    "berguna sebagai menjadikan kata dasar sebuah kalimat dan fungsi stemmer tersebut sekaligus menjadikan kalimat menjadi lower atau huruf kecil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steamingData(text):\n",
    "    steamingData = stemmer.stem(text)\n",
    "    return steamingData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[indoStopWord]\n",
    "\n",
    "berguna dalam menghilangkan kata sambung atau tidak diperlukan, ini berfungsi dlam menghitung kesamaan antar kalimat pada algoritma MMR agar lebih mudah dan mendapatkan hasil yang akurat (Lib NLTK & List Stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indoStopWord(stopNLTK, stopTxt, kalimat):\n",
    "    hasilStopWord = []\n",
    "    for kata in kalimat.split():\n",
    "        if not kata in stopNLTK:\n",
    "            if not kata in stopTxt:\n",
    "                hasilStopWord.append(kata)\n",
    "    return \" \".join(hasilStopWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[hasilSummary]\n",
    "\n",
    "fungsi yang berguna dalam menampilkan hasil summarization pada algoritma MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasilSummary(kalimatAsli, summarySet):\n",
    "    hasil = []\n",
    "    for sentence in summarySet:\n",
    "        hasil.append(kalimatAsli [sentence].lstrip(' ')) \n",
    "    return \" \".join(hasil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[visualisasiSummaryOri]\n",
    "\n",
    "menampilkan visualisasi yang sangat berguna dalam mengetahui kata mana saja yang dipakai atau ditampilkan pada summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualisasiSummaryOri(cleansingTeks,summarySet,kalimatAsli):\n",
    "    for sentence in cleansingTeks:\n",
    "        if sentence in summarySet:\n",
    "            print(colored(kalimatAsli[sentence].lstrip(' '),'red'))\n",
    "        else:\n",
    "            print(kalimatAsli[sentence].lstrip(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bisa dibilang sebagai code utama, dimana disini tempat menjalankan semua code dengan melakukan pemanggilan semua fungsi dan class algoritam MMR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization (data)\n",
    "    for iteration, article in enumerate(df['article']):\n",
    "        id = df['id'][iteration]\n",
    "        tokenizeKalimat = tokenizeParagraftoKalimat(article)\n",
    "\n",
    "        kalimat = []\n",
    "        cleansingTeks = []\n",
    "        kalimatAsli = {}\n",
    "\n",
    "        for teks in tokenizeKalimat:\n",
    "            kataDasar = steamingData(cleansingData(teks))\n",
    "            dataFinal = indoStopWord(load_stopWordsNLTK(),load_stopWords(),kataDasar)\n",
    "            cleansingTeks.append(dataFinal)\n",
    "            kalimat.append(teks)\n",
    "            kalimatAsli[dataFinal] = teks\n",
    "\n",
    "        iteration = MMR()\n",
    "        score = iteration.similarityScore(cleansingTeks)\n",
    "        summarySet = iteration.calculateMMR(score,cleansingTeks)\n",
    "\n",
    "\n",
    "        summary = hasilSummary(kalimatAsli,summarySet)\n",
    "        simpanSummary(mydb,summary,id)\n",
    "        print ('\\nSummary dari Berita ID : {} (hasil teks yang diringkas):\\n'.format(id))\n",
    "        print(summary)\n",
    "\n",
    "        print ('=============================================================')\n",
    "        print ('\\Oringinal Article (Teks Asli):\\n')\n",
    "        visualisasiSummaryOri(cleansingTeks,summarySet,kalimatAsli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-92c0fb6633d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummarization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-33c494a5c845>\u001b[0m in \u001b[0;36msummarization\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msummarization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mberita\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'article'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marticle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mberita\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtokenizeKalimat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizeParagraftoKalimat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "summarization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
