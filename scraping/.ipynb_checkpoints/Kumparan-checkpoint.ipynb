{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import Exception\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import mysql.connector\n",
    "import re\n",
    "import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Kumparan Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class dibawah merupakan proses pengambilan data dari website berita Kompas.com yang dimana pemanggilan semua fungsi dibawah tersebut nantinya akan dipanggil pada fungsi [scrapingDataKumparan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kumparan:\n",
    "     #deklarasi variable global\n",
    "    url = \"\"\n",
    "    mydb = \"\"\n",
    "    keyword = \"\"\n",
    "    urlDetailData = \"\"\n",
    "    date = \"\"\n",
    "    \n",
    "    #fungsi dari inisialisasi data saat memanggil class pertama kali\n",
    "    def __init__(self, urlBerita, pencarian,searchDate):\n",
    "        self.url = urlBerita\n",
    "        self.keyword = pencarian\n",
    "        try:\n",
    "            if(searchDate == \"\"):\n",
    "                self.date = \"\"\n",
    "            else:\n",
    "                self.date = datetime.datetime.strptime(searchDate, '%d-%m-%Y')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        self.mydb = mysql.connector.connect(host=\"localhost\",user=\"root\", password=\"\",database=\"db-berita-mca\")\n",
    "        \n",
    "    #fungsi menyimpan data ke database\n",
    "    def simpanDatabase(self,data):\n",
    "        mycursor = self.mydb.cursor()\n",
    "        sql = \"INSERT INTO tb_berita (media,judul_berita,label,penulis,release_date,url,content) VALUES (%s,%s,%s,%s,%s,%s,%s)\"\n",
    "        mycursor.execute(sql, data)\n",
    "        self.mydb.commit()\n",
    "        return\n",
    "    \n",
    "    #fungsi buat validasi data duplicate di database\n",
    "    def validasiDataDatabase(self,dataBerita):\n",
    "        mycursor = self.mydb.cursor()\n",
    "        sql = \"SELECT * FROM tb_berita WHERE url = %s\"\n",
    "        dataUrl = dataBerita\n",
    "        url = (dataBerita,)\n",
    "        mycursor.execute(sql, url)\n",
    "        myresult = mycursor.fetchall()\n",
    "        return myresult\n",
    "    \n",
    "    def getUrlDetail(self,page):\n",
    "        self.urlDetailData = []\n",
    "        for page in range(page): \n",
    "            if(self.keyword == \"\"):\n",
    "                urlGet = (self.url+\"/trending\")\n",
    "                soup = BeautifulSoup(get(urlGet).text, 'lxml')\n",
    "                getContent = soup.find('div','Viewweb__StyledView-sc-1ajfkkc-0 kshFXN')\n",
    "                groupContent = getContent.find_all('div','Viewweb__StyledView-sc-1ajfkkc-0 fswdpV')\n",
    "                for x in groupContent:\n",
    "                    news_url = x.find('a', href=True).get('href')\n",
    "                    mergeUrl = (self.url+news_url)\n",
    "                    self.urlDetailData.append(mergeUrl)\n",
    "            else:\n",
    "                urlGet = (self.url+\"/search/\"+self.keyword)\n",
    "                soup = BeautifulSoup(get(urlGet).text, 'lxml')\n",
    "                getContent = soup.find('div','Viewweb__StyledView-sc-1ajfkkc-0 dCdfue')\n",
    "                groupContent = getContent.find_all('div','Viewweb__StyledView-sc-1ajfkkc-0 fswdpV')\n",
    "                for x in groupContent:\n",
    "                    news_url = x.find('a', href=True).get('href')\n",
    "                    mergeUrl = (self.url+news_url)\n",
    "                    self.urlDetailData.append(mergeUrl)\n",
    "                    \n",
    "    def scrapingDataKumparan(self):\n",
    "        if(self.date == \"\"):                \n",
    "            self.getUrlDetail(5)\n",
    "            for dataBerita in self.urlDetailData:\n",
    "                myresult = self.validasiDataDatabase(dataBerita)\n",
    "                if(len(myresult)==0):\n",
    "                    try:\n",
    "                        media = \"Kumparan.com\"\n",
    "                        web_data = get(dataBerita)\n",
    "                        soup = BeautifulSoup(web_data.text, 'html.parser')\n",
    "                        page = soup.find('div','Viewweb__StyledView-sc-1ajfkkc-0 cKIaSV')\n",
    "                        title = page.find('h1','Textweb__StyledText-sc-1uxddwr-0 iVHMBA').text\n",
    "                        label = page.find('span','Textweb__StyledText-sc-1uxddwr-0 iaFPCN').text\n",
    "                        author = page.find('span','Textweb__StyledText-sc-1uxddwr-0 bvaEVS').text\n",
    "                        release_date = page.find('span','Textweb__StyledText-sc-1uxddwr-0 fbabON').text      \n",
    "                        groupContent = page.find('div','StoryRenderer__EditorWrapper-th08cs-0 ZDWZV')\n",
    "                        texts = groupContent.find_all('span','Textweb__StyledText-sc-1uxddwr-0 lmbERM')\n",
    "                        news_content = ' '.join([text.text for text in texts])           \n",
    "                        data = (media,title,label,author,release_date,dataBerita,news_content)\n",
    "                        self.simpanDatabase(data)\n",
    "                    except Exception as e:\n",
    "                        continue \n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "            print(\"no data in dateSearch\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://kumparan.com'\n",
    "# pencarian = ''\n",
    "# tanggal = '12-12-2021'\n",
    "# testing = Kumparan(url, pencarian,tanggal)\n",
    "# testing.scrapingDataKumparan()\n",
    "# testing.urlDetailData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
