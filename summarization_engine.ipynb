{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\risma\\Kuliah\\MCA\\Text-Summarization-News-Ariticles\\algoritma\\MMR.ipynb\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import import_ipynb\n",
    "import re\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import pandas as pd\n",
    "from algoritma.MMR import *\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from termcolor import colored\n",
    "import time\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deklarasi Connection Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat koneksi kedatabase lokal dengan database 'db-berita-mca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"db-berita-mca\"  \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat Fungsi Steaming Use Sastrawi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat stemmer pakai sastrawi \n",
    "Digunakan untuk melakukan steaming kalimat (menjadi kalimat dasar Menggunakan Library Sastrawi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Stopword Lib & File Internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengambil data stopword bahasa indonesia yang pertama menggunakan file list dari stop word 917 dan menggunakan library nltk sebanyak panjang data 789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopWords():\n",
    "    r = open(\"stopwordlist-indonesia.txt\", \"r\")\n",
    "    readTxt = r.read()\n",
    "    idStopWord = readTxt.split() \n",
    "    return idStopWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_stopWordsNLTK():\n",
    "    stop_words = stopwords.words('indonesian')\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpan hasil summary ke database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menyimpan data yang telah dihasilakan melalui summary ke database dengan cara mengupdate data tersebut dan memasukan text summary pada field tersebut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpanData(mydb,summary,id,labeling_summary,score_summary,labeling_content,score_content):\n",
    "    mycursor = mydb.cursor()\n",
    "    id = int(id)\n",
    "    sql = \"UPDATE tb_berita SET summary = %s ,labeling_summary = %s ,score_summary = %s,labeling_content = %s,score_content = %s WHERE id = %s\"\n",
    "    param = (summary,labeling_summary,score_summary,labeling_content,score_content,id)\n",
    "    mycursor.execute(sql, param)\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proses Text Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tokenizeParagraftoKalimat, cleansingData, steamingData, indoStopWord]\n",
    "\n",
    "Fungsi diatas merupakan fungsi yang digunakan untuk melakukan preprocessing article sebuah berita, penjelasan mengenai fungsi akan dijelaskan lebih lanjut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tokenizeParagraftoKalimat]\n",
    "\n",
    "berfungsi sebagai tokenize pargraf menjadi bagian perkalimat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeParagraftoKalimat(paragraf):\n",
    "    tokenize = sent_tokenize(paragraf)\n",
    "    return tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cleansingData]\n",
    "\n",
    "berfungsi sebagai membersihkan data dari huruf tanda petik dan masih kata besar atau keceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansingData(text):\n",
    "    hasil = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    hasil = hasil.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[steamingData]\n",
    "\n",
    "berguna sebagai menjadikan kata dasar sebuah kalimat dan fungsi stemmer tersebut sekaligus menjadikan kalimat menjadi lower atau huruf kecil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steamingData(text):\n",
    "    steamingData = stemmer.stem(text)\n",
    "    return steamingData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[indoStopWord]\n",
    "\n",
    "berguna dalam menghilangkan kata sambung atau tidak diperlukan, ini berfungsi dlam menghitung kesamaan antar kalimat pada algoritma MMR agar lebih mudah dan mendapatkan hasil yang akurat (Lib NLTK & List Stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indoStopWord(stopNLTK, stopTxt, kalimat):\n",
    "    hasilStopWord = []\n",
    "    for kata in kalimat.split():\n",
    "        if not kata in stopNLTK:\n",
    "            if not kata in stopTxt:\n",
    "                hasilStopWord.append(kata)\n",
    "    return \" \".join(hasilStopWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[hasilSummary]\n",
    "\n",
    "fungsi yang berguna dalam menampilkan hasil summarization pada algoritma MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasilSummary(kalimatAsli, summarySet):\n",
    "    hasil = []\n",
    "    for sentence in summarySet:\n",
    "        hasil.append(kalimatAsli [sentence].lstrip(' ')) \n",
    "    return \" \".join(hasil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[visualisasiSummaryOri]\n",
    "\n",
    "menampilkan visualisasi yang sangat berguna dalam mengetahui kata mana saja yang dipakai atau ditampilkan pada summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualisasiSummaryOri(cleansingTeks,summarySet,kalimatAsli):\n",
    "    for sentence in cleansingTeks:\n",
    "        if sentence in summarySet:\n",
    "            print(colored(kalimatAsli[sentence].lstrip(' '),'red'))\n",
    "        else:\n",
    "            print(kalimatAsli[sentence].lstrip(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bisa dibilang sebagai code utama, dimana disini tempat menjalankan semua code dengan melakukan pemanggilan semua fungsi dan class algoritam MMR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization (data):\n",
    "    for iteration, article in enumerate(data['article']):\n",
    "        id = df['id'][iteration]\n",
    "        tokenizeKalimat = tokenizeParagraftoKalimat(article)\n",
    "\n",
    "        kalimat = []\n",
    "        cleansingTeks = []\n",
    "        kalimatAsli = {}\n",
    "\n",
    "        for teks in tokenizeKalimat:\n",
    "            kataDasar = steamingData(cleansingData(teks))\n",
    "            dataFinal = indoStopWord(load_stopWordsNLTK(),load_stopWords(),kataDasar)\n",
    "            cleansingTeks.append(dataFinal)\n",
    "            kalimat.append(teks)\n",
    "            kalimatAsli[dataFinal] = teks\n",
    "\n",
    "        iteration = MMR()\n",
    "        score = iteration.similarityScore(cleansingTeks)\n",
    "        summarySet = iteration.calculateMMR(score,cleansingTeks)\n",
    "\n",
    "\n",
    "        summary = hasilSummary(kalimatAsli,summarySet)\n",
    "        polaritySummary,scoreSummary = analisisSummary(summary)\n",
    "        content = \" \".join(cleansingTeks)\n",
    "        polarityContent,scoreContent = analisisSummary(content)\n",
    "        simpanData(mydb,summary,id,polaritySummary,scoreSummary,polarityContent,scoreContent)\n",
    "        print ('\\nSummary dari Berita ID : {} (hasil teks yang diringkas):\\n'.format(id))\n",
    "        print(summary)\n",
    "        print ('\\nAnalisis Sentiment :'+polaritySummary)\n",
    "        print ('\\nDengan Score Sentiment :'+str(scoreSummary))  \n",
    "\n",
    "        print ('=============================================================')\n",
    "        print ('\\Oringinal Article (Teks Asli):\\n')\n",
    "        visualisasiSummaryOri(cleansingTeks,summarySet,kalimatAsli)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[analisisSummary] fungsi yang berguna untuk melakukan analysis sentiment menggunkaan model lexicon da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisisSummary(text):\n",
    "    lexicon_positive = dict()\n",
    "    with open('data/lexicon_positive.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            lexicon_positive[row[0]] = int(row[1])\n",
    "        \n",
    "    lexicon_negative = dict()\n",
    "    with open('data/lexicon_negative.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            lexicon_negative[row[0]] = int(row[1])\n",
    "            \n",
    "    tokonize = (word_tokenize(cleansingData(text)))\n",
    "    hasilStopWord = []\n",
    "    for kata in tokonize:\n",
    "        if not kata in load_stopWordsNLTK():\n",
    "            if not kata in load_stopWords():\n",
    "                hasilStopWord.append(kata)\n",
    "    hasilSteamingData = []\n",
    "    for x in hasilStopWord:\n",
    "        hasilSteamingData.append(steamingData(x))\n",
    "    score = 0\n",
    "    for word in hasilSteamingData:\n",
    "        if (word in lexicon_positive):\n",
    "            score = score + lexicon_positive[word]\n",
    "    for word in hasilStopWord:\n",
    "         if (word in lexicon_negative):\n",
    "            score = score + lexicon_negative[word]\n",
    "    polarity=''\n",
    "    if (score > 0):\n",
    "        polarity = 'positive'\n",
    "    elif (score < 0):\n",
    "        polarity = 'negative'\n",
    "    else:\n",
    "        polarity = 'neutral'\n",
    "        \n",
    "    return polarity,score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengambil Data pada Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengambil data pada database,data yang diambil hanya 2 kolom saja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2439</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Infeksi virus corona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                            article\n",
       "0  2439  Jakarta, CNBC Indonesia - Infeksi virus corona..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"SELECT id, content FROM tb_berita WHERE summary IS NULL\")\n",
    "myresult = mycursor.fetchall()\n",
    "df = pd.DataFrame(myresult,columns=['id','article'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary dari Berita ID : 2439 (hasil teks yang diringkas):\n",
      "\n",
      "Jakarta, CNBC Indonesia - Infeksi virus corona di Korea Selatan (Korsel) mencatat lebih dari 7.000 kasus selama tiga hari berturut-turut, Jumat (10/12/2021). Pejabat juga mengeluarkan perintah administratif yang mengharuskan rumah sakit di seluruh negeri mempersiapkan 2.000 atau lebih banyak tempat tidur yang digabungkan untuk perawatan Covid-19. Sekitar 41,5 juta orang, atau 81% dari populasi lebih dari 51 juta, telah divaksinasi lengkap, tetapi hanya 10% yang menerima suntikan booster.\n",
      "\n",
      "Analisis Sentiment :positive\n",
      "\n",
      "Dengan Score Sentiment :7\n",
      "=============================================================\n",
      "\\Oringinal Article (Teks Asli):\n",
      "\n",
      "\u001b[31mJakarta, CNBC Indonesia - Infeksi virus corona di Korea Selatan (Korsel) mencatat lebih dari 7.000 kasus selama tiga hari berturut-turut, Jumat (10/12/2021).\u001b[0m\n",
      "Jumlah ini memecahkan rekor dan membuat rumah sakit kelimpungan.\n",
      "Perdana Menteri Korsel Kim Boo-kyum mengatakan Korsel bisa mengambil tindakan luar biasa jika kenaikan kasus tidak segera melambat.\n",
      "\"Jika menjadi jelas bahwa kita tidak berhasil membalikkan situasi krisis ini dalam beberapa hari ke depan, pemerintah tidak akan punya pilihan lain selain menggunakan langkah-langkah anti-virus yang luar biasa, termasuk jarak sosial yang kuat,\" kata Kim, dilansir dari Associated Press (AP News).\n",
      "Sementara Wakil Menteri Kesehatan Lee Ki-il mengatakan para pejabat dapat mengurangi batas pertemuan sosial dan memulihkan pembatasan jam kerja di restoran dan bar jika keadaan terus terlihat buruk minggu depan.\n",
      "\"Kami akan mencoba yang terbaik untuk menghindari penguncian,\" kata Lee.\n",
      "\u001b[31mPejabat juga mengeluarkan perintah administratif yang mengharuskan rumah sakit di seluruh negeri mempersiapkan 2.000 atau lebih banyak tempat tidur yang digabungkan untuk perawatan Covid-19.\u001b[0m\n",
      "Kim mengatakan pemerintah juga akan mempercepat pemberian suntikan vaksin dengan memperpendek interval antara suntikan vaksin kedua dan ketiga dari empat atau lima bulan saat ini menjadi tiga bulan mulai minggu depan.\n",
      "\u001b[31mSekitar 41,5 juta orang, atau 81% dari populasi lebih dari 51 juta, telah divaksinasi lengkap, tetapi hanya 10% yang menerima suntikan booster.\u001b[0m\n",
      "Badan Pengendalian dan Pencegahan Penyakit (KDCA) Korea mengatakan sekitar 5.300 dari 7.022 kasus baru yang dilaporkan Jumat berasal dari ibu kota Seoul dan daerah metropolitan terdekat.\n",
      "Jumlah kematian negara itu sekarang mencapai 4.130 setelah 53 pasien virus meninggal dalam 24 jam terakhir, sementara 852 lainnya dalam kondisi serius atau kritis.\n",
      "Korea Selatan juga telah memperketat perbatasannya untuk mencegah varian omicron sejak mengidentifikasi kasus pertamanya pekan lalu.\n",
      "KDCA mengatakan petugas kesehatan mengkonfirmasi tiga infeksi omicron lagi pada hari Jumat, sehingga jumlahnya menjadi 63.\n",
      "Para ilmuwan mengatakan belum jelas apakah omicron lebih menular atau berbahaya daripada jenis virus sebelumnya.\n"
     ]
    }
   ],
   "source": [
    "summarization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
