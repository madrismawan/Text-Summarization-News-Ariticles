{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\risma\\Kuliah\\MCA\\Text-Summarization-News-Ariticles\\algoritma\\MMR.ipynb\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import import_ipynb\n",
    "import re\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import pandas as pd\n",
    "from algoritma.MMR import *\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from termcolor import colored\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deklarasi Connection Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat koneksi kedatabase lokal dengan database 'db-berita-mca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"db-berita-mca\"  \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat Fungsi Steaming Use Sastrawi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat stemmer pakai sastrawi \n",
    "Digunakan untuk melakukan steaming kalimat (menjadi kalimat dasar Menggunakan Library Sastrawi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Stopword Lib & File Internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengambil data stopword bahasa indonesia yang pertama menggunakan file list dari stop word 917 dan menggunakan library nltk sebanyak panjang data 789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopWords():\n",
    "    r = open(\"stopwordlist-indonesia.txt\", \"r\")\n",
    "    readTxt = r.read()\n",
    "    idStopWord = readTxt.split() \n",
    "    return idStopWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_stopWordsNLTK():\n",
    "    stop_words = stopwords.words('indonesian')\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpan hasil summary ke database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menyimpan data yang telah dihasilakan melalui summary ke database dengan cara mengupdate data tersebut dan memasukan text summary pada field tersebut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpanSummary(mydb,summary,id):\n",
    "    mycursor = mydb.cursor()\n",
    "    id = int(id)\n",
    "    sql = \"UPDATE tb_berita SET summary = %s WHERE id = %s\"\n",
    "    param = (summary,id)\n",
    "    mycursor.execute(sql, param)\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proses Text Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tokenizeParagraftoKalimat, cleansingData, steamingData, indoStopWord]\n",
    "\n",
    "Fungsi diatas merupakan fungsi yang digunakan untuk melakukan preprocessing article sebuah berita, penjelasan mengenai fungsi akan dijelaskan lebih lanjut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tokenizeParagraftoKalimat]\n",
    "\n",
    "berfungsi sebagai tokenize pargraf menjadi bagian perkalimat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeParagraftoKalimat(paragraf):\n",
    "    tokenize = sent_tokenize(paragraf)\n",
    "    return tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cleansingData]\n",
    "\n",
    "berfungsi sebagai membersihkan data dari huruf tanda petik dan masih kata besar atau keceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansingData(text):\n",
    "    hasil = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    hasil = hasil.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[steamingData]\n",
    "\n",
    "berguna sebagai menjadikan kata dasar sebuah kalimat dan fungsi stemmer tersebut sekaligus menjadikan kalimat menjadi lower atau huruf kecil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steamingData(text):\n",
    "    steamingData = stemmer.stem(text)\n",
    "    return steamingData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[indoStopWord]\n",
    "\n",
    "berguna dalam menghilangkan kata sambung atau tidak diperlukan, ini berfungsi dlam menghitung kesamaan antar kalimat pada algoritma MMR agar lebih mudah dan mendapatkan hasil yang akurat (Lib NLTK & List Stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indoStopWord(stopNLTK, stopTxt, kalimat):\n",
    "    hasilStopWord = []\n",
    "    for kata in kalimat.split():\n",
    "        if not kata in stopNLTK:\n",
    "            if not kata in stopTxt:\n",
    "                hasilStopWord.append(kata)\n",
    "    return \" \".join(hasilStopWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[hasilSummary]\n",
    "\n",
    "fungsi yang berguna dalam menampilkan hasil summarization pada algoritma MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasilSummary(kalimatAsli, summarySet):\n",
    "    hasil = []\n",
    "    for sentence in summarySet:\n",
    "        hasil.append(kalimatAsli [sentence].lstrip(' ')) \n",
    "    return \" \".join(hasil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[visualisasiSummaryOri]\n",
    "\n",
    "menampilkan visualisasi yang sangat berguna dalam mengetahui kata mana saja yang dipakai atau ditampilkan pada summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualisasiSummaryOri(cleansingTeks,summarySet,kalimatAsli):\n",
    "    for sentence in cleansingTeks:\n",
    "        if sentence in summarySet:\n",
    "            print(colored(kalimatAsli[sentence].lstrip(' '),'red'))\n",
    "        else:\n",
    "            print(kalimatAsli[sentence].lstrip(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bisa dibilang sebagai code utama, dimana disini tempat menjalankan semua code dengan melakukan pemanggilan semua fungsi dan class algoritam MMR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization (data):\n",
    "    for iteration, article in enumerate(data['article']):\n",
    "        id = df['id'][iteration]\n",
    "        tokenizeKalimat = tokenizeParagraftoKalimat(article)\n",
    "\n",
    "        kalimat = []\n",
    "        cleansingTeks = []\n",
    "        kalimatAsli = {}\n",
    "\n",
    "        for teks in tokenizeKalimat:\n",
    "            kataDasar = steamingData(cleansingData(teks))\n",
    "            dataFinal = indoStopWord(load_stopWordsNLTK(),load_stopWords(),kataDasar)\n",
    "            cleansingTeks.append(dataFinal)\n",
    "            kalimat.append(teks)\n",
    "            kalimatAsli[dataFinal] = teks\n",
    "\n",
    "        iteration = MMR()\n",
    "        score = iteration.similarityScore(cleansingTeks)\n",
    "        summarySet = iteration.calculateMMR(score,cleansingTeks)\n",
    "\n",
    "\n",
    "        summary = hasilSummary(kalimatAsli,summarySet)\n",
    "        simpanSummary(mydb,summary,id)\n",
    "        print ('\\nSummary dari Berita ID : {} (hasil teks yang diringkas):\\n'.format(id))\n",
    "        print(summary)\n",
    "\n",
    "        print ('=============================================================')\n",
    "        print ('\\Oringinal Article (Teks Asli):\\n')\n",
    "        visualisasiSummaryOri(cleansingTeks,summarySet,kalimatAsli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengambil Data pada Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengambil data pada database,data yang diambil hanya 2 kolom saja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Eksekutif Pfizer men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>769</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Kementerian Kesehata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Vaksin Sinovac merup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>771</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Terdeteksinya varian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>772</td>\n",
       "      <td>Jakarta, CNBC Indonesia - Inggris melaporkan l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1109</td>\n",
       "      <td>Liputan6.com, Jakarta - Bek Timnas Indonesia E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>1110</td>\n",
       "      <td>Liputan6.com, Los Angeles - Brian May mengumum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>1111</td>\n",
       "      <td>Liputan6.com, Den Haag - Belanda telah mengumu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1112</td>\n",
       "      <td>Liputan6.com, Jakarta - Aktor Taiwan pemenang ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>1113</td>\n",
       "      <td>Liputan6.com, Jakarta - Kementerian Investasi/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                            article\n",
       "0     768  Jakarta, CNBC Indonesia - Eksekutif Pfizer men...\n",
       "1     769  Jakarta, CNBC Indonesia - Kementerian Kesehata...\n",
       "2     770  Jakarta, CNBC Indonesia - Vaksin Sinovac merup...\n",
       "3     771  Jakarta, CNBC Indonesia - Terdeteksinya varian...\n",
       "4     772  Jakarta, CNBC Indonesia - Inggris melaporkan l...\n",
       "..    ...                                                ...\n",
       "341  1109  Liputan6.com, Jakarta - Bek Timnas Indonesia E...\n",
       "342  1110  Liputan6.com, Los Angeles - Brian May mengumum...\n",
       "343  1111  Liputan6.com, Den Haag - Belanda telah mengumu...\n",
       "344  1112  Liputan6.com, Jakarta - Aktor Taiwan pemenang ...\n",
       "345  1113  Liputan6.com, Jakarta - Kementerian Investasi/...\n",
       "\n",
       "[346 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"SELECT id, content FROM tb_berita WHERE summary IS NULL \")\n",
    "myresult = mycursor.fetchall()\n",
    "df = pd.DataFrame(myresult,columns=['id','article'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary dari Berita ID : 765 (hasil teks yang diringkas):\n",
      "\n",
      "Jakarta, CNBC Indonesia - Malaysia melaporkan tambahan 11 kasus varian baru covid-19 omicron. Terdiri dari tiga orang yang melakukan perjalanan dari Inggris, tiga dari Amerika Serikat (AS), dua dari Nigeria, dua dari Arab Saudi dan satu dari Australia. Kemudian, perayaan Malam Tahun Baru skala besar tidak diperbolehkan.\n",
      "=============================================================\n",
      "\\Oringinal Article (Teks Asli):\n",
      "\n",
      "\u001b[31mJakarta, CNBC Indonesia - Malaysia melaporkan tambahan 11 kasus varian baru covid-19 omicron.\u001b[0m\n",
      "Sehingga jumlah saat ini yang terdeteksi omicron menjadi 13 orang.\n",
      "Dilaporkan, 11 kasus Omicron baru ini adalah impor.\n",
      "\u001b[31mTerdiri dari tiga orang yang melakukan perjalanan dari Inggris, tiga dari Amerika Serikat (AS), dua dari Nigeria, dua dari Arab Saudi dan satu dari Australia.\u001b[0m\n",
      "Kemudian, satu kasus adalah orang Malaysia dan dua adalah orang Nigeria.\n",
      "Direktur Jenderal Kesehatan Malaysia Dr Noor Hisham Abdullah mengatakan, 11 kasus tersebut termasuk di antara 18 sampel yang menunjukkan dugaan adanya varian Omicron.\n",
      "\"Tujuh sampel lainnya, bagaimanapun, (kami) tidak dapat mengkonfirmasi keberadaan varian Omicron karena seluruh tes tidak dapat dilakukan karena tingkat viral load yang rendah dalam sampel,\" kata Dr Noor Hisham yang dikutip dari Channel News Asia, Minggu (19/12/2021).\n",
      "Dengan meningkatnya kasus Omicron ini, Otoritas Kesehatan Malaysia mengatakan, kebijakan pengendalian Covid-19 telah ditingkatkan di semua titik masuk internasional dan juga di masyarakat.\n",
      "Pertama yang diantisipasi adalah negara Nigeria yang ditetapkan sebagai negara berisiko tinggi.\n",
      "Sehingga para pelancong dari negara-negara ini harus memakai alat pelacak digital selama masa karantina wajib.\n",
      "Sementara itu, wisatawan yang tiba dari Inggris harus melakukan tes mandiri setiap hari selama karantina dan melaporkan hasilnya di aplikasi MySejahtera.\n",
      "\u001b[31mKemudian, perayaan Malam Tahun Baru skala besar tidak diperbolehkan.\u001b[0m\n",
      "Lalu orang-orang yang menghadiri acara-acara perayaan berskala kecil pun harus melakukan tes diri sebelumnya.\n",
      "Di sisi lain, Kementerian Kesehatan Malaysia juga mengimbau secara tegas agar masyarakat untuk segera mendapatkan suntikan vaksin Covid-19.\n",
      "\n",
      "Summary dari Berita ID : 766 (hasil teks yang diringkas):\n",
      "\n",
      "WHO menyebutkan, omicron menyebar dengan cepat di negara-negara dengan tingkat kekebalan populasi yang tinggi. Sehingga, saat ini sudah ada sebanyak 89 negara yang melaporkan adanya carian baru Covid-19 ini. Namun, masih banyak yang belum diketahui mengenai virus ini termasuk tingkat keparahan penyakit yang ditimbulkannya.\n",
      "=============================================================\n",
      "\\Oringinal Article (Teks Asli):\n",
      "\n",
      "Jakarta, CNBC Indonesia - Organisasi Kesehatan Dunia (WHO) melaporkan kasus varian Omicron telah meningkat dua kali lipat dalam 1,5 hari hingga 3 hari.\n",
      "\u001b[31mSehingga, saat ini sudah ada sebanyak 89 negara yang melaporkan adanya carian baru Covid-19 ini.\u001b[0m\n",
      "\u001b[31mWHO menyebutkan, omicron menyebar dengan cepat di negara-negara dengan tingkat kekebalan populasi yang tinggi.\u001b[0m\n",
      "Tetapi tidak jelas apakah ini karena kemampuan virus untuk menembus kekebalan, peningkatan transmisi penularan atau kombinasi keduanya.\n",
      "Adapun WHO pertama kali menetapkan Omicron sebagai virus yang perlu dikhawatirkan pada 26 November.\n",
      "\u001b[31mNamun, masih banyak yang belum diketahui mengenai virus ini termasuk tingkat keparahan penyakit yang ditimbulkannya.\u001b[0m\n",
      "\"Data keparahan Omicron masih terbatas.\n",
      "Lebih banyak data diperlukan untuk memahami profil keparahan dan bagaimana keparahan dipengaruhi oleh vaksinasi dan kekebalan yang sudah ada sebelumnya,\" ujar WHO yang dikutip dari channel news asia, Minggu (19/12/2021).\n",
      "\"Masih ada data terbatas yang tersedia, dan tidak ada bukti peer-review, tentang kemanjuran atau efektivitas vaksin hingga saat ini untuk Omicron,\" imbuhnya.\n",
      "Namun, di sisi lain WHO memperingatkan bahwa dengan kasus yang meningkat begitu cepat, rumah sakit bisa kewalahan seperti sebelumnya.\n",
      "Saat ini bahkan sudah ada beberapa negara yang rumah sakitnya mulai dipenuhi oleh pasien varian Omicron.\n",
      "\"Rawat inap di Inggris dan Afrika Selatan terus meningkat, dan mengingat jumlah kasus yang meningkat pesat, ada kemungkinan banyak sistem perawatan kesehatan menjadi cepat kewalahan,\" kata WHO.\n",
      "\n",
      "Summary dari Berita ID : 767 (hasil teks yang diringkas):\n",
      "\n",
      "Secara global, Covid-19 varian omicron telah dilaporkan di 89 negara dan jumlah kasus meningkat dua kali lipat dalam 1,5 hingga 3 hari di daerah dengan penularan komunitas, kata Organisasi Kesehatan Dunia (WHO), seperti dikutip dari CNBC International, Sabtu (18/12/2021). Adapun Omicron disalahkan sebagai pemicu kenaikan 80% kasus baru di London. WHO memperingatkan bahwa dengan kasus yang meningkat begitu cepat, rumah sakit bisa kewalahan di beberapa tempat.\n",
      "=============================================================\n",
      "\\Oringinal Article (Teks Asli):\n",
      "\n",
      "Jakarta, CNBC Indonesia - Varian Omicron B.1.1.529 yang pertama kali dilaporkan di Afrika Selatan telah menyebar ke berbagai negara di dunia termasuk Indonesia.\n",
      "Hingga 18 Desember 2021, setidaknya ada tiga kasus omicron yang ada di Indonesia.\n",
      "\u001b[31mSecara global, Covid-19 varian omicron telah dilaporkan di 89 negara dan jumlah kasus meningkat dua kali lipat dalam 1,5 hingga 3 hari di daerah dengan penularan komunitas, kata Organisasi Kesehatan Dunia (WHO), seperti dikutip dari CNBC International, Sabtu (18/12/2021).\u001b[0m\n",
      "\"Omicron menyebar dengan cepat di negara-negara dengan tingkat kekebalan populasi yang tinggi, tetapi tidak jelas apakah ini karena kemampuan virus untuk menghindari kekebalan, peningkatan penularan yang melekat atau kombinasi keduanya,\" kata WHO dalam sebuah pembaruan.\n",
      "Badan tersebut menetapkan omicron sebagai variant of concern pada 26 November, segera setelah pertama kali terdeteksi, dan masih banyak yang belum diketahui tentang hal itu, termasuk tingkat keparahan penyakit yang ditimbulkannya.\n",
      "\"Data keparahan klinis Omicron masih terbatas, lebih banyak data diperlukan untuk memahami profil keparahan dan bagaimana tingkat keparahan dipengaruhi oleh vaksinasi dan kekebalan yang sudah ada sebelumnya,\" kata WHO.\n",
      "Selain itu, WHO menambahkan jika data yang terbatas dan tidak ada bukti untuk preview tentang kemanjuran atau efektivitas vaksin hingga saat ini untuk Omicron.\n",
      "\u001b[31mWHO memperingatkan bahwa dengan kasus yang meningkat begitu cepat, rumah sakit bisa kewalahan di beberapa tempat.\u001b[0m\n",
      "Buktinya, rawat inap di Inggris dan Afrika Selatan terus meningkat, dan mengingat jumlah kasus yang meningkat pesat, ada kemungkinan banyak sistem perawatan kesehatan menjadi cepat kewalahan.\n",
      "Untuk diketahui, Inggris melaporkan ledakan infeksi Covid-19 tiga hari berturut-turut.\n",
      "Jumat (17/12/2021), kasus kembali memecahkan rekor baru, menjadi 93.045.\n",
      "\u001b[31mAdapun Omicron disalahkan sebagai pemicu kenaikan 80% kasus baru di London.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-92c0fb6633d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummarization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-9b0c66fbee19>\u001b[0m in \u001b[0;36msummarization\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mteks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenizeKalimat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mkataDasar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteamingData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleansingData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mteks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mdataFinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindoStopWord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_stopWordsNLTK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mload_stopWords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkataDasar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mcleansingTeks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-3a981b5e98e2>\u001b[0m in \u001b[0;36msteamingData\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msteamingData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msteamingData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msteamingData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\CachedStemmer.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mstems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelegatedStemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mstems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mstems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py\u001b[0m in \u001b[0;36mstem_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem_plural_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem_singular_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_plural\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py\u001b[0m in \u001b[0;36mstem_singular_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;34m\"\"\"Stem a singular word to its common stem form.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisitor_provider\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#step 1 - 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_stemming_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#step 6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36mstart_stemming_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;31m#step 4, 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_prefixes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36mremove_prefixes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mremove_prefixes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccept_prefix_visitors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefix_pisitors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36maccept_prefix_visitors\u001b[1;34m(self, visitors)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mremovalCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremovals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvisitor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvisitors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisitor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36maccept\u001b[1;34m(self, visitor)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maccept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mvisitor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maccept_visitors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisitors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Visitor\\AbstractDisambiguatePrefixRule.py\u001b[0m in \u001b[0;36mvisit\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdisambiguator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisambiguators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisambiguator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisambiguate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "summarization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
