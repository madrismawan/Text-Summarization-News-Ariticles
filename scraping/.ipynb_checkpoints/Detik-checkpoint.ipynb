{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import Exception\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import mysql.connector\n",
    "import re\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Detik Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class dibawah merupakan proses pengambilan data dari website berita Detik.com yang dimana pemanggilan semua fungsi dibawah tersebut nantinya akan dipanggil pada fungsi [scrapingDataDetik]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detik:  \n",
    "    #deklarasi variable global\n",
    "    url = \"\"\n",
    "    mydb = \"\"\n",
    "    keyword = \"\"\n",
    "    urlDetailData = \"\"\n",
    "    today = datetime.now()\n",
    "    \n",
    "    #fungsi dari inisialisasi data saat memanggil class pertama kali\n",
    "    def __init__(self, urlBerita, pencarian):\n",
    "        self.url = urlBerita\n",
    "        self.keyword = pencarian\n",
    "        self.mydb = mysql.connector.connect(host=\"localhost\",user=\"root\", password=\"\",database=\"db-berita-mca\")  \n",
    "    \n",
    "    #fungsi menyimpan data ke database\n",
    "    def simpanDatabase(self,data):\n",
    "        mycursor = self.mydb.cursor()\n",
    "        sql = \"INSERT INTO tb_berita (media,judul_berita,label,penulis,release_date,url,content) VALUES (%s,%s,%s,%s,%s,%s,%s)\"\n",
    "        mycursor.execute(sql, data)\n",
    "        self.mydb.commit()\n",
    "        return\n",
    "    \n",
    "    #fungsi buat validasi data duplicate di database\n",
    "    def validasiDataDatabase(self,dataBerita):\n",
    "        mycursor = self.mydb.cursor()\n",
    "        sql = \"SELECT * FROM tb_berita WHERE url = %s\"\n",
    "        dataUrl = dataBerita\n",
    "        url = (dataBerita,)\n",
    "        mycursor.execute(sql, url)\n",
    "        myresult = mycursor.fetchall()\n",
    "        return myresult\n",
    "\n",
    "    #fungsi buat ngambil jumlah page pada pencarian berita tersebut\n",
    "    def getPage(self):\n",
    "        if(self.keyword == \"\"):\n",
    "            try:\n",
    "                dateNow = today.strftime(\"%m/%d/%Y\")\n",
    "                urlGet = (\"https://news.detik.com/indeks/1?date=\"+dateNow)\n",
    "                soup = BeautifulSoup(get(urlGet).text, 'lxml')\n",
    "                getAllPage= soup.find('div','pagination text-center mgt-16 mgb-16')\n",
    "                page_link = getAllPage.select('a')\n",
    "                for page in page_link :\n",
    "                    if(page.text != \"Next\"):\n",
    "                        lastPage = page.text\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        else:\n",
    "            try:\n",
    "                dateNow = today.strftime(\"%m/%d/%Y\")\n",
    "                urlGet = (self.url+\"/search/searchall?query=\"+self.keyword+\"&fromdatex=\"+dateNow+\"&todatex=\"+dateNow)\n",
    "                soup = BeautifulSoup(get(urlGet).text, 'lxml')\n",
    "                getAllPage= soup.find('div','paging text_center')\n",
    "                page_link = getAllPage.select('a')\n",
    "                for page in page_link:\n",
    "                    if(page.text != \"\"):\n",
    "                        lastPage = page.text\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        return lastPage\n",
    "    \n",
    "    #ngambil semua url-detail pada scraping data\n",
    "    def getDetailUrl(self, page):\n",
    "        self.urlDetailData = []\n",
    "        for page in range(page): \n",
    "            if(self.keyword == \"\"):\n",
    "                dateNow = today.strftime(\"%m/%d/%Y\")\n",
    "                urlGet = (\"https://news.detik.com/indeks/\"+format(page+1)+\"?date=\"+dateNow)\n",
    "            else:\n",
    "                dateNow = today.strftime(\"%d/%m/%Y\")\n",
    "                urlGet = (self.url+\"/search/searchall?query=\"+self.keyword+\"&fromdatex=\"+dateNow+\"&todatex=\"+dateNow+\"&page={}\".format(page+1))\n",
    "            indeksPage = get(urlGet)\n",
    "            soup = BeautifulSoup(indeksPage.text, 'html.parser')\n",
    "            contents = soup.find_all('article')\n",
    "            for content in contents:\n",
    "                try:\n",
    "                    news_url = content.find('a', href=True).get('href')\n",
    "                    self.urlDetailData.append(news_url)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        return self.urlDetailData\n",
    "    \n",
    "    def scrapingDataDetik(self):\n",
    "        #disini aku deklarasiin manual pagenya kalau mau semua page berita yang diambil mati sudah ni engine wkwk\n",
    "        self.getDetailUrl(1)\n",
    "        for dataBerita in self.urlDetailData:\n",
    "            myresult = self.validasiDataDatabase(dataBerita)\n",
    "            if(len(myresult)==0):\n",
    "                try:\n",
    "                    web_data = get(dataBerita)\n",
    "                    soup = BeautifulSoup(web_data.text, 'html.parser')\n",
    "                    header = soup.find('article','detail')\n",
    "                    #Start cleansing judul berita solanya spacenya lebar kali\n",
    "                    title = header.find('h1','detail__title').text\n",
    "                    title = re.sub(r'\\s+', ' ',title)\n",
    "                    title = title.lstrip()\n",
    "                    #End cleansing judul berita\n",
    "                    author_class = header.find('div','detail__author').text.split(' ')\n",
    "                    authorOne = author_class[0]\n",
    "                    media = \"Detik.com\"\n",
    "                    label = soup.find('div','page__breadcrumb')\n",
    "                    label = label.find('a',href=True).text\n",
    "                    author = (authorOne+\" & \")+\"\".join(author_class[:2])\n",
    "                    release_date = header.find('div', class_='detail__date').text\n",
    "                    detail_text_class = soup.find('div', class_='detail__body-text')\n",
    "                    texts = detail_text_class.find_all('p')\n",
    "                    news_content = ' '.join([text.text for text in texts])\n",
    "                    data = (media,title,label,author,release_date,dataBerita,news_content)\n",
    "                    self.simpanDatabase(data)\n",
    "                    print(title)\n",
    "                except Exception as e:\n",
    "                    continue    \n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://finance.detik.com/sosok/d-5859109/3-srikandi-di-daftar-orang-terkaya-indonesia',\n",
       " 'https://finance.detik.com/fintech/d-5859145/daya-tarik-nft-kian-cerah-pemain-di-ri-makin-banyak',\n",
       " 'https://finance.detik.com/bursa-dan-valas/d-5858858/omicron-masuk-ri-ihsg-pagi-ini-turun-tipis-ke-6587',\n",
       " 'https://finance.detik.com/berita-ekonomi-bisnis/d-5858673/ramalan-harga-emas-dan-saham-usai-omicron-masuk-ri']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.detik.com'\n",
    "keyword = 'saham'\n",
    "\n",
    "detik = Detik(url,keyword)\n",
    "detik.getDetailUrl(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
