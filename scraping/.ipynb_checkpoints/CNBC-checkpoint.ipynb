{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import Exception\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import mysql.connector\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Scraping Data CNBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class dibawah merupakan proses pengambilan data dari website berita CNBC yang dimana pemanggilan semua fungsi dibawah tersebut nantinya akan dipanggil pada fungsi [scrapingDataBeritaCNBC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNBC:\n",
    "    #deklarasi variable global\n",
    "    url = \"\"\n",
    "    mydb = \"\"\n",
    "    keyword = \"\"\n",
    "    urlDetailData = \"\"\n",
    "    date = \"\"\n",
    "    \n",
    "    #fungsi dari inisialisasi data saat memanggil class pertama kali\n",
    "    def __init__(self, urlBerita, pencarian,searchDate):\n",
    "        self.url = urlBerita\n",
    "        self.keyword = pencarian\n",
    "        try:\n",
    "            if(searchDate == \"\"):\n",
    "                self.date = datetime.datetime.now()\n",
    "            else:\n",
    "                self.date = datetime.datetime.strptime(searchDate, '%d-%m-%Y')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        self.mydb = mysql.connector.connect(host=\"localhost\",user=\"root\", password=\"\",database=\"db-berita-mca\")  \n",
    "    \n",
    "    #fungsi menyimpan data ke database\n",
    "    def simpanDatabase(self,data):\n",
    "        mycursor = self.mydb.cursor()\n",
    "        sql = \"INSERT INTO tb_berita (media,judul_berita,label,penulis,release_date,url,content) VALUES (%s,%s,%s,%s,%s,%s,%s)\"\n",
    "        mycursor.execute(sql, data)\n",
    "        self.mydb.commit()\n",
    "        return\n",
    "    \n",
    "    #fungsi buat validasi data duplicate di database\n",
    "    def validasiDataDatabase(self,dataBerita):\n",
    "        mycursor = self.mydb.cursor()\n",
    "        sql = \"SELECT * FROM tb_berita WHERE url = %s\"\n",
    "        dataUrl = dataBerita\n",
    "        url = (dataBerita,)\n",
    "        mycursor.execute(sql, url)\n",
    "        myresult = mycursor.fetchall()\n",
    "        return myresult\n",
    "    \n",
    "    #fungsi buat ngambil jumlah page pada pencarian berita tersebut\n",
    "    def getAllPageWebsite(self):\n",
    "        if(self.keyword == \"\"):\n",
    "            urlGet = (self.url+\"/indeks?date=\"+self.date.strftime(\"%Y/%m/%d\"))\n",
    "        else:\n",
    "            urlGet = (self.url+\"/search?query=\"+self.keyword+\"&date=\"+self.date.strftime(\"%Y/%m/%d\"))\n",
    "        try:\n",
    "            soup = BeautifulSoup(get(urlGet).text, 'lxml')\n",
    "            getAllPage= soup.find('div','paging text_center gtm_paging')\n",
    "            page_link = getAllPage.select('a')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        try:\n",
    "            for page in page_link:\n",
    "                if(page.text != \"\"):\n",
    "                    lastPage = page.text\n",
    "            return lastPage\n",
    "        except Exception as e:\n",
    "            print(\"Tidak Terdapat Data pada Pencarian anda tersebut\")\n",
    "            \n",
    "    \n",
    "    #ngambil semua url-detail pada scraping data\n",
    "    def getUrlInPage(self,page):\n",
    "        self.urlDetailData = []\n",
    "        for page in range(page):\n",
    "            try:\n",
    "                if(self.keyword == \"\"):\n",
    "                    urlGet = (self.url+\"/indeks/{}\".format(page+1)+\"?date=\"+self.date.strftime(\"%Y/%m/%d\"))\n",
    "    #                 print(urlGet)\n",
    "                else:\n",
    "                    urlGet = (self.url+\"/search?query=\"+self.keyword+\"&p={}\".format(page+1)+\"&date=\"+self.date.strftime(\"%Y/%m/%d\"))\n",
    "            except Exception as e:\n",
    "                print(\"format tanggal anda masukan salah\")\n",
    "                break\n",
    "            indeksPage = get(urlGet)\n",
    "            soup = BeautifulSoup(indeksPage.text, 'html.parser')\n",
    "            contents = soup.find_all('article')\n",
    "            for content in contents:\n",
    "                try:\n",
    "                    news_url = content.find('a', href=True).get('href')\n",
    "                    self.urlDetailData.append(news_url)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        return self.urlDetailData\n",
    "    \n",
    "    \n",
    "    #Fungsi utama buat scraping semua data tersebut\n",
    "    def scrapingDataBeritaCNBC(self):\n",
    "        #disini aku deklarasiin manual pagenya kalau mau semua page berita yang diambil mati sudah ni engine wkwk\n",
    "        self.getUrlInPage(5)\n",
    "        for dataBerita in self.urlDetailData:\n",
    "            myresult = self.validasiDataDatabase(dataBerita)\n",
    "            if(len(myresult)==0):\n",
    "                try:\n",
    "                    web_data = get(dataBerita)\n",
    "                    soup = BeautifulSoup(web_data.text, 'html.parser')\n",
    "                    header = soup.find('div', class_='jdl')\n",
    "                    media = \"CBNC Indonesia\"\n",
    "                    title = header.find('h1').text\n",
    "                    author_class = header.find('div', class_='author').text.split(' ')\n",
    "                    label = author_class[0]\n",
    "                    author = ' '.join(author_class[2:])\n",
    "                    release_date = header.find('div', class_='date').text\n",
    "                    detail_text_class = soup.find('div', class_='detail_text')\n",
    "                    texts = detail_text_class.find_all('p')\n",
    "                    news_content = ' '.join([text.text for text in texts])\n",
    "\n",
    "                    data = (media,title,label,author,release_date,dataBerita,news_content)\n",
    "                    self.simpanDatabase(data)\n",
    "                except Exception as e:\n",
    "                    continue    \n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.cnbcindonesia.com/news/20211012220341-4-283438/percepat-klaim-bpjs-kesehatan-dorong-rs-lengkapi-berkas',\n",
       " 'https://www.cnbcindonesia.com/news/20211012203456-4-283426/hampir-50-gadis-gadis-di-china-ogah-menikah-kenapa',\n",
       " 'https://www.cnbcindonesia.com/market/20211012204726-17-283427/wall-street-dibuka-berayun-ke-zona-merah',\n",
       " 'https://www.cnbcindonesia.com/news/20211012202743-4-283425/dana-mega-proyek-kereta-cepat-bengkak-begini-rinciannya',\n",
       " 'https://www.cnbcindonesia.com/news/20211012202229-4-283424/parahnya-india-krisis-energi-gara-gara-batu-bara',\n",
       " 'https://www.cnbcindonesia.com/news/20211012201327-4-283423/proyek-kereta-cepat-bengkak-ada-terowongan-tak-tembus-bor',\n",
       " 'https://www.cnbcindonesia.com/news/20211012200640-4-283422/krisis-batu-bara-china-india-hadapi-krisis-energi-terburuk',\n",
       " 'https://www.cnbcindonesia.com/news/20211012195932-4-283421/ada-ancaman-lebih-ngeri-dari-covid-asia-bisa-terendam-laut',\n",
       " 'https://www.cnbcindonesia.com/tech/20211012164204-37-283375/gaet-indomaret-telkomsel-zyrex-hadirkan-laptop-untuk-siswa',\n",
       " 'https://www.cnbcindonesia.com/news/20211012192415-4-283416/butuh-modal-usaha-begini-cara-gadai-bpkb-di-pegadaian',\n",
       " 'https://www.cnbcindonesia.com/market/20211012195627-17-283420/dow-futures-melemah-tipis-jelang-rilis-laporan-keuangan',\n",
       " 'https://www.cnbcindonesia.com/news/20211012194305-4-283419/tim-luhut-soal-proyek-kereta-cepat-bengkak-ini-skenarionya',\n",
       " 'https://www.cnbcindonesia.com/lifestyle/20211012194120-33-283418/perdana-twice-masuk-billboard-hot-100',\n",
       " 'https://www.cnbcindonesia.com/news/20211012193141-4-283417/inikah-kota-raksasa-baru-yang-dilewati-kereta-cepat-jkt-bdg',\n",
       " 'https://www.cnbcindonesia.com/news/20211012175730-16-283400/cek-persyaratan-umroh-terbaru-ke-arab-saudi-untuk-jamaah-ri',\n",
       " 'https://www.cnbcindonesia.com/news/20211012191603-4-283415/gempa-magnitudo-63-guncang-lagi-pulau-kreta-di-yunani',\n",
       " 'https://www.cnbcindonesia.com/news/20211012185347-8-283411/soal-pembengkakan-biaya-kereta-cepatini-kata-anak-buah-luhut',\n",
       " 'https://www.cnbcindonesia.com/news/20211012190546-4-283414/tren-temuan-harta-karun-migas-ri-naik-sejak-2019-lho',\n",
       " 'https://www.cnbcindonesia.com/news/20211012190505-4-283412/umroh-mau-dibuka-lagi-agen-travel-banyak-kesulitan-uang',\n",
       " 'https://www.cnbcindonesia.com/tech/20211012180437-40-283401/waspada-masalah-jantung-pasca-pulih-dari-covid-19',\n",
       " 'https://www.cnbcindonesia.com/news/20211012183727-4-283409/pemerintah-uji-coba-pembukaan-bali-riau-untuk-wna',\n",
       " 'https://www.cnbcindonesia.com/market/20211012183533-17-283408/sentimen-negatif-menyeruak-lagi-harga-sbn-berbalik-menguat',\n",
       " 'https://www.cnbcindonesia.com/news/20211012174140-8-283395/freeport-membangun-smelter-hingga-proyeksi-ekonomi-as',\n",
       " 'https://www.cnbcindonesia.com/tech/20211012183241-37-283410/apa-kabar-rencana-merger-indosat-tri-ini-bocoran-kominfo',\n",
       " 'https://www.cnbcindonesia.com/tech/20211012182922-37-283406/genshin-impact-punya-2-karakter-baru-arataki-itto-gorou',\n",
       " 'https://www.cnbcindonesia.com/news/20211012183014-4-283407/umroh-dibuka-lagi-siap-siap-biaya-bisa-bengkak',\n",
       " 'https://www.cnbcindonesia.com/news/20211012181829-4-283404/terungkap-ini-penyebab-83-kasus-covid-di-pon-xx-papua',\n",
       " 'https://www.cnbcindonesia.com/market/20211012152441-17-283328/aksi-profit-taking-buat-harga-timah-tergelincir',\n",
       " 'https://www.cnbcindonesia.com/market/20211012182552-17-283405/ini-bukti-konkret-covid-19-mulai-punah-dari-indonesia',\n",
       " 'https://www.cnbcindonesia.com/investment/20211012180548-21-283402/live-now-saham-emiten-batu-bara-on-fire-awas-nyangkut',\n",
       " 'https://www.cnbcindonesia.com/news/20211012175234-16-283398/duh-nanjak-lagi-kasus-covid-19-ri-hari-ini-tembus-1261',\n",
       " 'https://www.cnbcindonesia.com/news/20211012181117-4-283403/jamaah-ri-sudah-bisa-umroh-kapan-waktunya',\n",
       " 'https://www.cnbcindonesia.com/news/20211012161949-4-283359/kabar-baik-2130-pasien-covid-19-di-ri-sembuh-hari-ini',\n",
       " 'https://www.cnbcindonesia.com/market/20211012155053-19-283345/pandemi-sekar-bumi-perluas-ekspor-diversifikasi-produk',\n",
       " 'https://www.cnbcindonesia.com/news/20211012175053-4-283397/jokowi-bangga-ri-ada-smelter-terbesar-dunia-faisal-so-what',\n",
       " 'https://www.cnbcindonesia.com/tech/20211012175419-37-283399/instagram-down-berjam-jam-facebook-uji-senjata-rahasia-ini']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.cnbcindonesia.com\"\n",
    "keyword = \"\"\n",
    "# format tanggal day-month-years 25-12-2021\n",
    "tanggal = \"12-10-2021\"\n",
    "scrapCNBC = CNBC(url,keyword,tanggal)\n",
    "scrapCNBC.getUrlInPage(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
